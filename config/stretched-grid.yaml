defaults:
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none
  - _self_
  
start_date: 2023-11-24T12:00:00 # Sort out multi-step input under the hood?
end_date: 2023-11-24T18:00:00

checkpoint_path: /lustre/storeB/project/nwp/bris/aram/ckpt/new-ref-SG-reduced-grid.ckpt

num_leadtimes: 12 # Number of leadtimes including initial state as leadtime 0
timestep: 6h # Model timestep, fetch from checkpoint
frequency: 6h # Dataset frequency

dataset:
  cutout: 
    - dataset: #Path to dataset 
    - dataset: #Path to dataset 
  min_distance_km: 0
  adjust: all 

deterministic: True #Move to code

# If the user wants to release GPU cache and memory
# This option releases unused cached/memory used by torch
#release_cache: False

# Determine how much the encoder and decoder is chunked
inference_num_chunks: 32

dataloader:
  #Create defaults so that these entries do not have to be in the config
  batch_size: 1 #Always 1 for inference
  prefetch_factor: 2
  num_workers: 1
  pin_memory: True #For gpu

  read_group_size: 1 # Remove

  predict:
    #Move this to the config parser
    dataset: ${dataset}
    start: ${start_date}
    end: ${end_date}

  datamodule:
    _target_: anemoi.training.data.dataset.NativeGridDataset #Document these options
    _convert_: all

hardware:
  paths:
    data: /lustre/storeB/project/nwp/bris/datasets/
  files:
    lam_dataset: aifs-meps-2.5km-2020-2024-6h-v6.zarr
    global_dataset: aifs-od-an-oper-0001-mars-n320-2023-2024-6h-v2.zarr
    dataset_obs: name_of_dataset

  num_gpus_per_node: 1
  num_gpus_per_model: 1
  num_nodes: 1

model:
  _target_: bris.model.BrisPredictor
  _convert_: all

routing:
  - decoder_index: 0
    domain: 0
    outputs:
      - netcdf:
          filename_pattern: meps_pred_%Y%m%dT%HZ.nc
          variables: [2t, 2d]
  - decoder_index: 0
    domain: 1
    outputs:
      - netcdf:
          filename_pattern: era_pred_%Y%m%dT%HZ.nc
          variables: [2t, 2d]

